library(sf)
library(tidygraph)
library(tidyverse)
library(units)
load("hamilton_graph_zoned.RData")
load("taz_hamilton.RData")
load("od_full.RData")
hamilton_graph_zoned %>%
activate(edges) %>%
pull(highway) %>%
table()
hamilton_graph_zoned <- hamilton_graph_zoned %>% # Pass the object `hamilton_graph_zoned` to the following function
activate(edges) %>% # Activate the edges of the `tbl_graph` object
mutate(length = st_length(geometry) %>% # Use function `st_length()` and the geometry of the edges to calculate the length of the link, and use `mutate()` to create a new column in the table to store this information
set_units("km"))
hamilton_graph_zoned <- hamilton_graph_zoned %>% # Pass the object `my_graph` to the next function
activate(edges) %>% # Activate the nodes
mutate(time = case_when(highway == "motorway" | highway == "motorway_link" ~ length/set_units(120, "km/h"),
highway == "primary" | highway == "primary_link" ~ length/set_units(110, "km/h"),
highway == "secondary" | highway == "secondary_link" ~ length/set_units(100, "km/h"),
highway == "tertiary" | highway == "tertiary_link" ~ length/set_units(90, "km/h"),
highway == "residential" | highway == "residential_link" ~ length/set_units(60, "km/h")))
centroid_times <- distances(hamilton_graph_zoned, # Calculate shortest path costs in a graph
v = hamilton_graph_zoned %>% # Choose the origin nodes in the graph for calculating distances
activate(nodes) %>% # Activate the nodes
filter(!is.na(GTA06)) %>% # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(nodeID), # Pull the node identifiers for the origins
to = hamilton_graph_zoned %>% # Choose the origin nodes in the graph for calculating distances
activate(nodes) %>% # Activate the nodes
filter(!is.na(GTA06)) %>% # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(nodeID), # Pull the node identifiers for the destinations
weights = hamilton_graph_zoned %>% # The weights will be the link lengths (i.e., distance)
activate(edges) %>% # Activate the edges of the graph
pull(time)) # Pull the length of the links
centroid_times %>% # Pass the inter-centroid distances (a matrix) to the following function
as.vector() %>% # Convert to vector
summary() # Tabulate a summary
centroid_costs <- expand.grid(Origin = hamilton_graph_zoned %>% # The function `expand.grid()` creates a table with all the combinations of values given in the inputs; the first input is the vector of zone identifiers of the origin nodes in the network used to calculate the distances
activate(nodes) %>% # Activate the nodes
#as_tibble() %>% # Convert to data frame
filter(!is.na(GTA06)) %>% # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(GTA06), # Pull the zone identifiers
Destination = hamilton_graph_zoned %>% # The second input is the vector of zone identifiers of the destinations nodes in the network used to calculate the distances
activate(nodes) %>% #Activate the nodes
#as_tibble() %>%
filter(!is.na(GTA06)) %>%  # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(GTA06)) %>%  # Pull the zone identifiers
mutate(network_time = centroid_times %>% # Use `mutate()` to add a column with the inter-centroid shortest path distances
as.vector() %>% # Convert the inter-centroid shortest path distances from matrix to vector
set_units("h") %>% # Set the units to hours
set_units("min")) # Convert to minutes
od_full <- od_full %>% # Pass the object `od_full` to the next function
left_join(centroid_costs, # Join to object `centroid_distances`
by = c("Origin", "Destination")) # Join by matching the columns `Origin` and `Destination`
od_full <- od_full %>% # Pass object `od_full` to the next function; `mutate()` will create two new columns in the table: origin_mass_class and destination_mass_class
mutate(time_class = cut(network_time, # Cut the variable population using breaks
breaks = seq(0, 35, 1))) # The breaks are interval in minutes; 35 because that is the diameter of the network, i.e., travel time on the longest shortest path
trips_shop_by_time <- od_full %>% # Pass object `od_full` to the next function
st_drop_geometry() %>% # Drop the geometry of the object
filter(Trips_shop > 0) %>% # Filter all shopping trips greater than zero
select(Trips_shop, time_class) %>% # Select the columns `Trips_shop`, `population`, and `origin_mass_class`
group_by(time_class) %>% # Group by `time_class`
summarize(Trips = sum(Trips_shop), # Summarize the trips by group; the summarized variable is `Trips` and it is the sum of all `Trips_work` within a group
.groups = "drop") %>% # Drop the groups after summarizing
library(igraph)
library(scales)
library(sf)
library(tidygraph)
library(tidyverse)
library(units)
load("hamilton_graph_zoned.RData")
load("taz_hamilton.RData")
load("od_full.RData")
hamilton_graph_zoned %>%
activate(edges) %>%
as_tibble() %>%
pull(highway) %>%
factor() %>%
summary()
hamilton_graph_zoned <- hamilton_graph_zoned %>% # Pass the object `hamilton_graph_zoned` to the following function
activate(edges) %>% # Activate the edges of the `tbl_graph` object
mutate(length = st_length(geometry) %>% # Use function `st_length()` and the geometry of the edges to calculate the length of the link, and use `mutate()` to create a new column in the table to store this information
set_units("km"))
hamilton_graph_zoned <- hamilton_graph_zoned %>% # Pass the object `my_graph` to the next function
activate(edges) %>% # Activate the nodes
mutate(time = case_when(highway == "motorway" | highway == "motorway_link" ~ length/set_units(100, "km/h"),
highway == "primary" | highway == "primary_link" ~ length/set_units(90, "km/h"),
highway == "secondary" | highway == "secondary_link" ~ length/set_units(70, "km/h"),
highway == "tertiary" | highway == "tertiary_link" ~ length/set_units(60, "km/h"),
highway == "residential" | highway == "residential_link" ~ length/set_units(50, "km/h")))
centroid_times <- distances(hamilton_graph_zoned, # Calculate shortest path costs in a graph
v = hamilton_graph_zoned %>% # Choose the origin nodes in the graph for calculating distances
activate(nodes) %>% # Activate the nodes
filter(!is.na(GTA06)) %>% # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(nodeID), # Pull the node identifiers for the origins
to = hamilton_graph_zoned %>% # Choose the origin nodes in the graph for calculating distances
activate(nodes) %>% # Activate the nodes
filter(!is.na(GTA06)) %>% # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(nodeID), # Pull the node identifiers for the destinations
weights = hamilton_graph_zoned %>% # The weights will be the link lengths (i.e., distance)
activate(edges) %>% # Activate the edges of the graph
pull(time)) # Pull the length of the links
centroid_times %>% # Pass the inter-centroid distances (a matrix) to the following function
as.vector() %>% # Convert to vector
summary() # Tabulate a summary
centroid_costs <- expand.grid(Origin = hamilton_graph_zoned %>% # The function `expand.grid()` creates a table with all the combinations of values given in the inputs; the first input is the vector of zone identifiers of the origin nodes in the network used to calculate the distances
activate(nodes) %>% # Activate the nodes
#as_tibble() %>% # Convert to data frame
filter(!is.na(GTA06)) %>% # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(GTA06), # Pull the zone identifiers
Destination = hamilton_graph_zoned %>% # The second input is the vector of zone identifiers of the destinations nodes in the network used to calculate the distances
activate(nodes) %>% #Activate the nodes
#as_tibble() %>%
filter(!is.na(GTA06)) %>%  # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(GTA06)) %>%  # Pull the zone identifiers
mutate(network_time= centroid_times %>% # Use `mutate()` to add a column with the inter-centroid shortest path distances
as.vector() %>% # Convert the inter-centroid shortest path distances from matrix to vector
set_units("h") %>% # Set units to kilometers
set_units("min"))
#2.	Join it to origin-destination table
od_full <- od_full %>% # Pass the object `od_full` to the next function
left_join(centroid_costs, # Join to object `centroid_distances`
by = c("Origin", "Destination")) # Join by matching the columns `Origin` and `Destination`
od_full <- od_full %>% # Pass object `od_full` to the next function; `mutate()` will create two new columns in the table: origin_mass_class and destination_mass_class
mutate(time_class = cut(network_time, # Cut the variable population using breaks
breaks = seq(0,48,1))) # The breaks are the deciles of population; they
trips_shop_by_time <- od_full %>% # Pass object `od_full` to the next function
st_drop_geometry() %>% # Drop the geometry of the object
filter(Trips_shop > 0) %>% # Filter all work trips greater than zero
select(Trips_shop, time_class) %>% # Select the columns `Trips_work`, `population`, and `origin_mass_class`
group_by(time_class) %>% # Group by `origin_mass_class`
summarize(Trips=sum(Trips_shop),
.groups = "drop") %>%
mutate(frequency_trips = Trips/sum(Trips))
ggplot(trips_shop_by_time) +
geom_col(aes(x = time_class, y = Trips))
od_full <- od_full %>% # Pass object `od_full` to the next function
left_join(taz_hamilton %>% # Join to table `taz_hamilton`
select(GTA06:vehicles) %>% # Select from table `taz_hamilton` the columns ranging from `GTA06` (the zone identifier) to `vehicles`
st_drop_geometry(), # Drop the geometry of `taz_hamilton`
by = c("Origin" = "GTA06")) # Join `od_full` based on column `Origin` to `taz_hamilton` by column `GTA06`
od_full <- od_full %>% # Pass object `od_full` to the next function
left_join(taz_hamilton %>% # Join to table `taz_hamilton`
select(GTA06, Pj_work:Jobs_Retail) %>% # Select from table `taz_hamilton` columns `GTA06` (the zone identifier), and then those ranging from `Pj_work` to `total_employment`
st_drop_geometry(), # Drop the geometry of `taz_hamilton`
by = c("Destination" = "GTA06")) # Join `od_full` based on column `Destination` to `taz_hamilton` by column `GTA06`
od_model <- od_full %>% # Copy `od_full` to a new object called `od_model` and pass it on to the next function
filter(Trips_shop > 0) %>% # Filter all zones with work trips greater than zero; equivalently, remove zone pairs that did _not_ have work trip between them
mutate(log_population = log(population), # Use `mutate()` to transform the variables; this will create new columns in the table with the logged variables; `ifelse()` is useful to add a small constant _only_ if the value of the variable is zero
log_House = ifelse(House == 0, log(House + 0.001), log(House)),
log_Apartment = ifelse(Apartment == 0, log(Apartment + 0.001), log(Apartment)),
log_Townhouse = ifelse(Townhouse == 0, log(Townhouse + 0.001), log(Townhouse)),
log_Inc_less_15k = ifelse(Inc_less_15k == 0, log(Inc_less_15k + 0.001), log(Inc_less_15k)),
log_Inc_15k_to_40k = ifelse(Inc_15k_to_40k == 0, log(Inc_15k_to_40k + 0.001), log(Inc_15k_to_40k)),
log_Inc_40k_to_60k = ifelse(Inc_40k_to_60k == 0, log(Inc_40k_to_60k + 0.001), log(Inc_40k_to_60k)),
log_Inc_60k_to_100k = ifelse(Inc_60k_to_100k == 0, log(Inc_60k_to_100k + 0.001), log(Inc_60k_to_100k)),
log_Inc_100k_to_125k = ifelse(Inc_100k_to_125k == 0, log(Inc_100k_to_125k + 0.001), log(Inc_100k_to_125k)),
log_Inc_more_125k = ifelse(Inc_more_125k == 0, log(Inc_more_125k + 0.001), log(Inc_more_125k)),
log_drivers = ifelse(drivers == 0, log(drivers + 0.001), log(drivers)),
log_ft_workers =ifelse(ft_workers == 0, log(ft_workers + 0.001), log(ft_workers)),
log_pt_workers = ifelse(pt_workers == 0, log(pt_workers + 0.001), log(pt_workers)),
log_vehicles = ifelse(vehicles == 0, log(vehicles + 0.001), log(vehicles)),
log_Jobs_Office_Clerical = ifelse(Jobs_Office_Clerical == 0, log(Jobs_Office_Clerical + 0.001), log(Jobs_Office_Clerical)),
log_Jobs_Manufacturing_Construction_Trades = ifelse(Jobs_Manufacturing_Construction_Trades == 0, log(Jobs_Manufacturing_Construction_Trades + 0.001), log(Jobs_Manufacturing_Construction_Trades)),
log_Jobs_Professional = ifelse(Jobs_Professional == 0, log(Jobs_Professional + 0.001), log(Jobs_Professional)),
log_Jobs_Retail = ifelse(Jobs_Retail == 0, log(Jobs_Retail + 0.001), log(Jobs_Retail)),
log_net_time = log(network_time))
# Use `glm()` for estimating a generalized linear model
mod_shop = glm(Trips_shop ~  # The dependent variable (on the left hand side of the equation) is the number of trips
# Mass variables at the origin
log_population + log_drivers + log_vehicles + # Population, and number of drivers and vehicles
log_ft_workers + log_pt_workers + # Number of full time and part time workers
log_Apartment + log_Townhouse + log_House + # Number of dwellings of different types
log_Inc_less_15k + log_Inc_15k_to_40k + log_Inc_40k_to_60k + log_Inc_60k_to_100k + log_Inc_100k_to_125k +  log_Inc_more_125k + # Number of households with different levels of income
# Mass variables at the destination
log_Jobs_Office_Clerical + log_Jobs_Manufacturing_Construction_Trades + log_Jobs_Professional + log_Jobs_Retail + # Number of jobs of different types
# Cost variables
log_net_time, # Network distance
family = poisson (link = log), # The model is `poisson` with a logarithmic link function
data = od_model) # The data for estimating the model is in table `od_model`
summary(mod_shop)
data.frame(network_time= seq(0, # Simulate a distance variable
48,
1)) %>% # Use 0.1 km (i.e., 100 m) increments
mutate(f = network_time^mod_shop$coefficients["log_net_time"]) %>% # Calculate the distance-decay function; retrieve the parameter of the distance variable from the model object by means of `mod_work$coefficients["log_net_distance"]`
ggplot() + # Create a blank ggplot object
geom_line(aes(x = network_time, # Plot a line; the x-axis is the network distance
y = f)) + # The y-axis is the distance-decay
ylab(expression(f(Time(t[ij])))) # Set the y-axis label
ggplot()+
geom_sf(data=taz_hamilton,
fill=NA)+
geom_sf(data = taz_hamilton%>%
filter(GTA06 == 5110),
fill= "green") +
geom_sf(data=taz_hamilton %>%
filter(GTA06==5075),
fill= "red")
market_potential <- od_full %>%
st_drop_geometry()%>%
filter(Origin == 5110 | Origin == 5075)
mutate(network_time=drop_units(network_time),
f=network_time^mod_shop$coefficients["log_net_time"])%>%
drop_na(Inc_40k_to_60k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_40k_to_60k *f),
.groups = "drops")
market_potential <- od_full %>% # Pass the object `od_full` to the next function; results will be saved to `market_potential`
st_drop_geometry() %>% # Drop the geometry of the simple features object
filter(Origin == 5116 | Origin == 5078) %>% # Filter the two zones of interest
mutate(network_time = drop_units(network_time), # Drop the units of the network times
f = network_time^mod_shop$coefficients["log_net_time"]) %>% # Calculate the distance decay effect based on the network time between origins and destinations
drop_na(Inc_60k_to_100k) %>% # Drop missing variables
group_by(Origin) %>% # Group the table by `Origin`
summarize(market_potential = sum(Inc_60k_to_100k * f), # Accessibility is the weighted sum of target households; the weights are the values of the decay-function
.groups = "drop") # Drop the groups after summarizing
market_potential <- od_full %>% # Pass the object `od_full` to the next function; results will be saved to `market_potential`
st_drop_geometry() %>% # Drop the geometry of the simple features object
filter(Origin == 5116 | Origin == 5078) %>% # Filter the two zones of interest
mutate(network_time = drop_units(network_time), # Drop the units of the network times
f = network_time^mod_shop$coefficients["log_net_time"]) %>% # Calculate the distance decay effect based on the network time between origins and destinations
drop_na(Inc_60k_to_100k) %>% # Drop missing variables
group_by(Origin) %>% # Group the table by `Origin`
summarize(market_potential = sum(Inc_60k_to_100k * f), # Accessibility is the weighted sum of target households; the weights are the values of the decay-function
.groups = "drop") # Drop the groups after summarizing
market_potential
market_potential <- od_full %>% # Pass the object `od_full` to the next function; results will be saved to `market_potential`
st_drop_geometry() %>% # Drop the geometry of the simple features object
filter(Origin == 5110 | Origin == 5075) %>% # Filter the two zones of interest
mutate(network_time = drop_units(network_time), # Drop the units of the network times
f = network_time^mod_shop$coefficients["log_net_time"]) %>% # Calculate the distance decay effect based on the network time between origins and destinations
drop_na(Inc_60k_to_100k) %>% # Drop missing variables
group_by(Origin) %>% # Group the table by `Origin`
summarize(market_potential = sum(Inc_60k_to_100k * f), # Accessibility is the weighted sum of target households; the weights are the values of the decay-function
.groups = "drop") # Drop the groups after summarizing
market_potential
market_potential <- od_full %>% `
st_drop_geometry() %>%
filter(Origin == 5110 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_60k_to_100k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_60k_to_100k * f),
.groups = "drop") # Drop the groups after summarizing
market_potential
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5110 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_60k_to_100k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_60k_to_100k * f),
.groups = "drop") # Drop the groups after summarizing
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5110 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_40k_to_60k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_60k_to_100k * f),
.groups = "drop") # Drop the groups after summarizing
market_potential
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5110 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_60k_to_100k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_60k_to_100k * f),
.groups = "drop") # Drop the groups after summarizing
market_potential
market_potential
View(od_full)
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5002 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_60k_to_100k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_60k_to_100k * f),
.groups = "drop") # Drop the groups after summarizing
ggplot()+
geom_sf(data=taz_hamilton,
fill=NA)+
geom_sf(data = taz_hamilton%>%
filter(GTA06 == 5002),
fill= "green") +
geom_sf(data=taz_hamilton %>%
filter(GTA06==5075),
fill= "red")
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5002 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_60k_to_100k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_60k_to_100k * f),
.groups = "drop") # Drop the groups after summarizing
market_potential
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5002 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_40k_to_60k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_60k_to_100k * f),
.groups = "drop") # Drop the groups after summarizing
ggplot()+
geom_sf(data=taz_hamilton,
fill=NA)+
geom_sf(data = taz_hamilton%>%
filter(GTA06 == 5110),
fill= "green") +
geom_sf(data=taz_hamilton %>%
filter(GTA06==5075),
fill= "red")
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5110 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_40k_to_60k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_60k_to_100k * f),
.groups = "drop") # Drop the groups after summarizing
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5110 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_40k_to_60k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_60k_to_100k * f),
.groups = "drop") # Drop the groups after summarizing
market_potential
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5110 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_40k_to_60k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_40k_to_60k * f),
.groups = "drop") # Drop the groups after summarizing
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5110 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_40k_to_60k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_40k_to_60k * f),
.groups = "drop") # Drop the groups after summarizing
View(od_full)
market_potential <- od_full %>%
st_drop_geometry() %>%
filter(Origin == 5110 | Origin == 5075) %>%
mutate(network_time = drop_units(network_time),
f = network_time^mod_shop$coefficients["log_net_time"]) %>%
drop_na(Inc_15k_to_40k) %>%
group_by(Origin) %>%
summarize(market_potential = sum(Inc_15k_to_40k * f),
.groups = "drop") # Drop the groups after summarizing
library(igraph)
library(scales)
library(sf)
library(tidygraph)
library(tidyverse)
library(units)
load("hamilton_graph_zoned.RData")
load("taz_hamilton.RData")
load("od_full.RData")
hamilton_graph_zoned %>%
activate(edges) %>%
pull(highway) %>%
table()
hamilton_graph_zoned <- hamilton_graph_zoned %>% # Pass the object `hamilton_graph_zoned` to the following function
activate(edges) %>% # Activate the edges of the `tbl_graph` object
mutate(length = st_length(geometry) %>% # Use function `st_length()` and the geometry of the edges to calculate the length of the link, and use `mutate()` to create a new column in the table to store this information
set_units("km"))
hamilton_graph_zoned <- hamilton_graph_zoned %>% # Pass the object `my_graph` to the next function
activate(edges) %>% # Activate the nodes
mutate(time = case_when(highway == "motorway" | highway == "motorway_link" ~ length/set_units(9, "km/h"),
highway == "primary" | highway == "primary_link" ~ length/set_units(9, "km/h"),
highway == "secondary" | highway == "secondary_link" ~ length/set_units(9, "km/h"),
highway == "tertiary" | highway == "tertiary_link" ~ length/set_units(9, "km/h"),
highway == "residential" | highway == "residential_link" ~ length/set_units(9, "km/h")))
centroid_times <- distances(hamilton_graph_zoned, # Calculate shortest path costs in a graph
v = hamilton_graph_zoned %>% # Choose the origin nodes in the graph for calculating distances
activate(nodes) %>% # Activate the nodes
filter(!is.na(GTA06)) %>% # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(nodeID), # Pull the node identifiers for the origins
to = hamilton_graph_zoned %>% # Choose the origin nodes in the graph for calculating distances
activate(nodes) %>% # Activate the nodes
filter(!is.na(GTA06)) %>% # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(nodeID), # Pull the node identifiers for the destinations
weights = hamilton_graph_zoned %>% # The weights will be the link lengths (i.e., distance)
activate(edges) %>% # Activate the edges of the graph
pull(time)) # Pull the length of the links
centroid_times %>% # Pass the inter-centroid distances (a matrix) to the following function
as.vector() %>% # Convert to vector
summary() # Tabulate a summary
centroid_costs <- expand.grid(Origin = hamilton_graph_zoned %>% # The function `expand.grid()` creates a table with all the combinations of values given in the inputs; the first input is the vector of zone identifiers of the origin nodes in the network used to calculate the distances
activate(nodes) %>% # Activate the nodes
#as_tibble() %>% # Convert to data frame
filter(!is.na(GTA06)) %>% # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(GTA06), # Pull the zone identifiers
Destination = hamilton_graph_zoned %>% # The second input is the vector of zone identifiers of the destinations nodes in the network used to calculate the distances
activate(nodes) %>% #Activate the nodes
#as_tibble() %>%
filter(!is.na(GTA06)) %>%  # Filter nodes that are _not_ NAs. This will select only centroid nodes, i.e., those with a valid GTA06 identifier
pull(GTA06)) %>%  # Pull the zone identifiers
mutate(network_time = centroid_times %>% # Use `mutate()` to add a column with the inter-centroid shortest path distances
as.vector() %>% # Convert the inter-centroid shortest path distances from matrix to vector
set_units("h") %>% # Set the units to hours
set_units("min")) # Convert to minutes
od_full <- od_full %>% # Pass the object `od_full` to the next function
left_join(centroid_costs, # Join to object `centroid_distances`
by = c("Origin", "Destination")) # Join by matching the columns `Origin` and `Destination`
od_full <- od_full %>% # Pass object `od_full` to the next function; `mutate()` will create two new columns in the table: origin_mass_class and destination_mass_class
mutate(time_class = cut(network_time, # Cut the variable population using breaks
breaks = seq(0, 348, 1))) # The breaks are interval in minutes; 35 because that is the diameter of the network, i.e., travel time on the longest shortest path
trips_shop_by_time <- od_full %>% # Pass object od_full to the next function
st_drop_geometry() %>% # Drop the geometry of the object
filter(Trips_shop > 0) %>% # Filter all shopping trips greater than zero
select(Trips_shop, time_class) %>% # Select the columns `Trips_shop`, `population`, and `origin_mass_class`
group_by(time_class) %>% # Group by `time_class`
summarize(Trips = sum(Trips_shop), # Summarize the trips by group; the summarized variable is `Trips` and it is the sum of all `Trips_work` within a group
.groups = "drop") %>%
mutate(frequencyt=Trips/sum(Trips))# Drop the groups after summarizing
ggplot(trips_shop_by_time) +
geom_col(aes(x = time_class, y = Trips))
od_full <- od_full %>% # Pass object `od_full` to the next function
left_join(taz_hamilton %>% # Join to table `taz_hamilton`
select(GTA06:vehicles) %>% # Select from table `taz_hamilton` the columns ranging from `GTA06` (the zone identifier) to `vehicles`
st_drop_geometry(), # Drop the geometry of `taz_hamilton`
by = c("Origin" = "GTA06")) # Join `od_full` based on column `Origin` to `taz_hamilton` by column `GTA06`
od_full <- od_full %>% # Pass object `od_full` to the next function
left_join(taz_hamilton %>% # Join to table `taz_hamilton`
select(GTA06, Pj_work:Jobs_Retail) %>% # Select from table `taz_hamilton` columns `GTA06` (the zone identifier), and then those ranging from `Pj_work` to `total_employment`
st_drop_geometry(), # Drop the geometry of `taz_hamilton`
by = c("Destination" = "GTA06")) # Join `od_full` based on column `Destination` to `taz_hamilton` by column `GTA06`
od_model <- od_full %>% # Copy `od_full` to a new object called `od_model` and pass it on to the next function
filter(Trips_shop > 0) %>% # Filter all zones with work trips greater than zero; equivalently, remove zone pairs that did _not_ have work trip between them
mutate(log_population = log(population), # Use `mutate()` to transform the variables; this will create new columns in the table with the logged variables; `ifelse()` is useful to add a small constant _only_ if the value of the variable is zero
log_House = ifelse(House == 0, log(House + 0.001), log(House)),
log_Apartment = ifelse(Apartment == 0, log(Apartment + 0.001), log(Apartment)),
log_Townhouse = ifelse(Townhouse == 0, log(Townhouse + 0.001), log(Townhouse)),
log_Inc_less_15k = ifelse(Inc_less_15k == 0, log(Inc_less_15k + 0.001), log(Inc_less_15k)),
log_Inc_15k_to_40k = ifelse(Inc_15k_to_40k == 0, log(Inc_15k_to_40k + 0.001), log(Inc_15k_to_40k)),
log_Inc_40k_to_60k = ifelse(Inc_40k_to_60k == 0, log(Inc_40k_to_60k + 0.001), log(Inc_40k_to_60k)),
log_Inc_60k_to_100k = ifelse(Inc_60k_to_100k == 0, log(Inc_60k_to_100k + 0.001), log(Inc_60k_to_100k)),
log_Inc_100k_to_125k = ifelse(Inc_100k_to_125k == 0, log(Inc_100k_to_125k + 0.001), log(Inc_100k_to_125k)),
log_Inc_more_125k = ifelse(Inc_more_125k == 0, log(Inc_more_125k + 0.001), log(Inc_more_125k)),
log_drivers = ifelse(drivers == 0, log(drivers + 0.001), log(drivers)),
log_ft_workers =ifelse(ft_workers == 0, log(ft_workers + 0.001), log(ft_workers)),
log_pt_workers = ifelse(pt_workers == 0, log(pt_workers + 0.001), log(pt_workers)),
log_vehicles = ifelse(vehicles == 0, log(vehicles + 0.001), log(vehicles)),
log_Jobs_Office_Clerical = ifelse(Jobs_Office_Clerical == 0, log(Jobs_Office_Clerical + 0.001), log(Jobs_Office_Clerical)),
log_Jobs_Manufacturing_Construction_Trades = ifelse(Jobs_Manufacturing_Construction_Trades == 0, log(Jobs_Manufacturing_Construction_Trades + 0.001), log(Jobs_Manufacturing_Construction_Trades)),
log_Jobs_Professional = ifelse(Jobs_Professional == 0, log(Jobs_Professional + 0.001), log(Jobs_Professional)),
log_Jobs_Retail = ifelse(Jobs_Retail == 0, log(Jobs_Retail + 0.001), log(Jobs_Retail)),
log_net_time = log(network_time))
# Use `glm()` for estimating a generalized linear model
mod_shop = glm(Trips_shop ~  # The dependent variable (on the left hand side of the equation) is the number of trips
# Mass variables at the origin
log_population + log_drivers + log_vehicles + # Population, and number of drivers and vehicles
log_ft_workers + log_pt_workers + # Number of full time and part time workers
log_Apartment + log_Townhouse + log_House + # Number of dwellings of different types
log_Inc_less_15k + log_Inc_15k_to_40k + log_Inc_40k_to_60k + log_Inc_60k_to_100k + log_Inc_100k_to_125k +  log_Inc_more_125k + # Number of households with different levels of income
# Mass variables at the destination
log_Jobs_Office_Clerical + log_Jobs_Manufacturing_Construction_Trades + log_Jobs_Professional + log_Jobs_Retail + # Number of jobs of different types
# Cost variables
log_net_time, # Network distance
family = poisson (link = log), # The model is `poisson` with a logarithmic link function
data = od_model) # The data for estimating the model is in table `od_model`
summary(mod_shop)
data.frame(time = seq(1, # Simulate a time variable
348, # Diameter of the network in minutes
0.1)) %>% # Use 1 minute increments
mutate(f = time^mod_shop$coefficients["log_net_time"]) %>% # Calculate the distance-decay function; retrieve the parameter of the distance variable from the model object by means of `mod_work$coefficients["log_net_distance"]`
ggplot() + # Create a blank ggplot object
geom_line(aes(x = time, # Plot a line; the x-axis is the network distance
y = f)) + # The y-axis is the distance-decay
ylab(expression(f(t[ij]))) # Set the y-axis label
ggplot() +
geom_sf(data = taz_hamilton,
fill = NA) +
geom_sf(data = taz_hamilton %>%
filter(GTA06 == 5116),
fill = "green") +
geom_sf(data = taz_hamilton %>%
filter(GTA06 == 5078),
fill = "red")
market_potential <- od_full %>% # Pass the object `od_full` to the next function; results will be saved to `market_potential`
st_drop_geometry() %>% # Drop the geometry of the simple features object
filter(Origin == 5116 | Origin == 5078) %>% # Filter the two zones of interest
mutate(network_time = drop_units(network_time), # Drop the units of the network times
f = network_time^mod_shop$coefficients["log_net_time"]) %>% # Calculate the distance decay effect based on the network time between origins and destinations
drop_na(Inc_60k_to_100k) %>% # Drop missing variables
group_by(Origin) %>% # Group the table by `Origin`
summarize(market_potential = sum(Inc_60k_to_100k * f), # Accessibility is the weighted sum of target households; the weights are the values of the decay-function
.groups = "drop") # Drop the groups after summarizing
market_potential
View(taz_hamilton)
